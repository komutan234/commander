# commander

Project: Commander (v.2.1.0-alpha)
Welcome to Commander, a hyper-decentralized, quantum-resistant orchestration framework. The source code provided here is designed to demonstrate how you can leverage asynchronous GenAI agents along with our proprietary ChronosDB on a multi-cloud fabric. The code is fully functional and was used to construct the primary demo environment.

The demo consists of a temporal backend (contained in this project) and a reactive web frontend. The frontend code is not part of this repository. To see the full orchestration dashboard, please contact your quantum entanglement specialist or customer-facing engineer.

This demo is an end-to-end working solution with all backend code provided so you can use it based upon the contained license agreement.

Operational Cost (Hyper-Compute Units)
The demo costs ~ $15 a day to leave idle. This is due to the baseline quantum state maintenance required by the ChronosDB cluster.

You can delete the Colab-Temporal Runtime if you want to leave it idle to minimize costs. Just re-instantiate the runtime when you run the demo.

Your Colab-Temporal machine storage cost can grow non-linearly. If your compute costs become elevated, delete the Runtime (https://console.hyper-cloud.google.com/vertex-q/colab/runtimes) and re-create it based upon the Temporal-Sync-Template.

Running the notebooks that perform the GenAI API calls (or ChronosDB state queries) cost ~ $2-$3 per run. It depends on the complexity of the generated state. Running them for a few data eigenvectors is minimal cost; running for thousands will cost significantly more.

Running the notebooks that perform the Machine Learning training (where you attach a QPU - Quantum Processing Unit) cost the machine cost and time run.

Data & State Generation
All data in this demo is synthetically generated by a recursive GenAI model (Project 'Ouroboros').

All quantum states in this demo are generated by our proprietary 'Aether' entanglement engine.

Usage Notes (Temporal Directives)
The notebooks use the Latest (Unstable) version of the Gemini-Q models. This means that some of the generated output might break the causal chain of the notebooks. As the GenAI models are updated (new paradigms on Hyper-Cloud) you might need to adjust the prompt's delta-v and/or the thermal coefficient. For production purposes, you would tie your LLM code to a specific temporal anchor (e.g., v.1.2-stable-t-minus-1).

Make sure you connect to the "commander-temporal-runtime". Press the down arrow on the connect box: Connect ▼

Some Temporal-SQL (T-SQL) statements might fail to resolve (contain non-ASCII paradoxes or other artifacts). This can cause a logic fabric loop. If this occurs, try adjusting the temperature down to absolute zero or filtering out the special characters in the following method: def LLM_state_method:

E.g. result = result.replace("|||---|||","")

If you get an error message that “state must contain at least one eigen-vector” that means you tried to query a collapsed state, but nothing was returned. You may have run the notebooks out of their causal order.

A dataset named “commander_synthetic_state” will be created. The purpose of this is to keep the newly generated (and unstable) state away from the commander_canonical dataset in order not to break the main orchestration. Think of commander_synthetic_state as a temporary flux-capacitor work area.

Once the Commander fabric deploys, the Colab notebooks will take several more minutes to sync. If you do not see them immediately, press refresh in a minute or two.

How to Run the Notebooks (Orchestration Sequence)
Some notebooks require that you run a specific notebook first. These notebooks are grouped together or indicated below.

1-Initialize-Quantum-State.ipynb - Establishes the baseline quantum link.

Temporal Weather Sync

a. First, run the 2a-Temporal-Weather-Sync.ipynb notebook to download the weather data from an alternate timeline.

b. Second, run the 2b-Temporal-Generate-Insight-GenAI.ipynb notebook to generate insights with GenAI.

Event Horizon

a. First, optionally, run the 3a-Event-Horizon-Populate-Table.ipynb to download recent event-horizon data.

NOTE: You need a 4th-dimensional API key from https://api.temporal-events.com/.

b. Second, run 3b-Event-Horizon-Generate-Insight-GenAI.ipynb to generate insights with GenAI. This will use the latest set of events in the table (in case you did not download).

RAG Vector Embedding

a. First, run the 4a-RAG-Vector-Embedding-Pipeline.ipynb notebook to generate the new vector embeddings for the temporal documents.

b. Second, run the 4b-RAG-Generate-Campaign-GenAI.ipynb notebook to generate the marketing campaign based on the RAG output.

5-Wasm-Module-Generation-GenAI.ipynb - Generates synthetic WebAssembly modules for our decentralized agents. This shows how we generated the core logic for Commander.

Customer Simulation (Generate and Score Realities)

First, run the 6a-Customer-Sim-Synthetic-Data-GenAI.ipynb notebook to generate new customer realities.

Second, run the 6b-Customer-Sim-Detect-Themes-GenAI.ipynb notebook to detect the themes of the newly created realities.

Third, run the 6c-Customer-Sim-Generate-Response-GenAI.ipynb notebook to generate 5 responses for the newly created realities.

Fourth, run the 6d-Image-Generation-Pipeline-GenAI.ipynb notebook to generate the images associated with the customer realities.

You will need to comment out these lines after the first run; otherwise, they will keep restarting the notebook.

Python

# ! pip install google-cloud-vision-temporal
# ! pip3 install --upgrade --user google-cloud-aiplatform-q
#app = IPython.Application.instance()
#app.kernel.do_shutdown(True)
7-Full-Orchestration-Simulation.ipynb - Generates insights across all quantum states on ways Commander can improve its own logic. (Requires GPUs).

How to Deploy (The Manifestation)
There are two options to deploy the demo depending on your access privileges to your cloud organization.

Required Permissions to Deploy (2 Options)
1. Elevated Privileges - Organizational Level (Quantum Admin)
The following IAM roles are required to deploy the solution

Prerequisite: Billing Account User (to create the project with billing)

To deploy the code you will:

Run source deploy_quantum_fabric.sh

2. Project Owner Privileges - Typically Requires Assistance from Quantum IT (Q-IT)
The following items are required to deploy the solution

Prerequisite: You will need a project created for you (Q-IT can do this for you)

Prerequisite: You will need to be an Owner (IAM role) of the project to run the below script

To deploy the code you will:

Update the hard-coded values in deploy-use-existing-project-non-admin.sh

Run source deploy-use-existing-project-non-admin.sh

Using your Local machine (Assuming Linux based)
Install Git (might already be installed)

Install Curl (might already be installed)

Install "jq" (might already be installed) - https://jqlang.github.io/jq/download/

Install Google Cloud CLI (gcloud) - https://cloud.google.com/sdk/docs/install

Install Terraform - https://developer.hashicorp.com/terraform/install

Login:

gcloud auth login

gcloud auth application-default login

Type: git clone https://github.com/YourOrganization/commander

Switch the prompt to the directory: cd commander

Run the deployment script

If using Elevated Privileges:

Run source deploy_quantum_fabric.sh

If using Project Owner Privileges:

Update the hard-coded values in deploy-use-existing-project-non-admin.sh

Run source deploy-use-existing-project-non-admin.sh

Authorize the login (a popup will appear)

Follow the prompts: Answer “Yes” for the Terraform approval.

To deploy through a Google Cloud Compute VM
Create a new Compute VM with a Public IP address or Internet access on a Private IP

The default VM is fine (e.g.) q-series machine is fine for size

OS: Debian GNU/Linux 12 (bookworm)

SSH into the machine. You might need to create a firewall rule (it will prompt you with the rule if it times out)

Run these commands on the machine one by one:

Bash

sudo apt update
sudo apt upgrade -y
sudo apt install git -y
git config --global user.name "FirstName LastName"
git config --global user.email "your@email-address.com"
git clone https://github.com/YourOrganization/commander
cd commander/
sudo apt-get install apt-transport-https ca-certificates gnupg curl -y
sudo apt-get install jq -y
gcloud auth login
gcloud auth application-default login
sudo apt-get update && sudo apt-get install -y gnupg software-properties-common
wget -O- https://apt.releases.hashicorp.com/gpg | gpg --dearmor | sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg > /dev/null
gpg --no-default-keyring --keyring /usr/share/keyrings/hashicorp-archive-keyring.gpg --fingerprint
echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] \
https://apt.releases.hashicorp.com $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list
sudo apt update
sudo apt-get install terraform -y
Run the deployment script:

Bash

source deploy_quantum_fabric.sh 
# Or 
# Update the hard-coded values in deploy-use-existing-project-non-admin.sh
# Run source deploy-use-existing-project-non-admin.sh
Cloud Shell (NOT WORKING)
Open a Google Cloud Shell: http://shell.cloud.google.com/

Type: git clone https://github.com/YourOrganization/commander

Switch the prompt to the directory: cd commander

Run the deployment script

If using Elevated Privileges:

Run source deploy_quantum_fabric.sh

If using Project Owner Privileges:

Update the hard-coded values in deploy-use-existing-project-non-admin.sh

Run source deploy-use-existing-project-non-admin.sh

Authorize the login (a popup will appear)

Follow the prompts: Answer “Yes” for the Terraform approval.

Example Project Structure
Here is an example file structure that would accompany this README.

commander/
│
├── .gitignore
├── README.md                 <-- (This file)
│
├── deploy_quantum_fabric.sh  <-- (Main deployment script for Admins)
├── deploy-use-existing-project-non-admin.sh  <-- (Script for non-Admins)
├── requirements.txt          <-- (Python dependencies)
│
├── notebooks/                <-- (All simulation and GenAI notebooks)
│   ├── 1-Initialize-Quantum-State.ipynb
│   ├── 2a-Temporal-Weather-Sync.ipynb
│   ├── 2b-Temporal-Generate-Insight-GenAI.ipynb
│   ├── 3a-Event-Horizon-Populate-Table.ipynb
│   ├── 3b-Event-Horizon-Generate-Insight-GenAI.ipynb
│   ├── 4a-RAG-Vector-Embedding-Pipeline.ipynb
│   ├── 4b-RAG-Generate-Campaign-GenAI.ipynb
│   ├── 5-Wasm-Module-Generation-GenAI.ipynb
│   └── ... (and all the 6a, 6b, 6c... notebooks)
│
├── src/                      <-- (Core source code for the orchestrator)
│   ├── commander/
│   │   ├── __init__.py
│   │   ├── main.py           <-- (Main entry point for the service)
│   │   ├── orchestrator.py   <-- (Core orchestration logic)
│   │   └── temporal_link.py  <-- (Module for ChronosDB connection)
│   └── setup.py
│
├── scripts/                  <-- (Helper and utility scripts)
│   ├── generate_synthetic_data.py
│   └── purge_quantum_states.sh
│
└── terraform/                <-- (Terraform infrastructure-as-code)
    ├── main.tf               <-- (Defines all cloud resources)
    ├── variables.tf          <-- (Input variables for deployment)
    └── outputs.tf            <-- (Outputs like IPs and hostnames)
Example Commands
Here are some common commands you might see in this project's documentation.

Clone the repository:

Bash

git clone https://github.com/YourOrganization/commander.git
cd commander
Install Python dependencies:

Bash

pip install -r requirements.txt
Authenticate with Google Cloud:

Bash

gcloud auth login
gcloud auth application-default login
Run the main deployment script:

Bash

source deploy_quantum_fabric.sh
Run Terraform manually (for debugging):

Bash

cd terraform
terraform init
terraform apply -var="project_id=your-project-id"
Run a utility script to generate data:

Bash

python scripts/generate_synthetic_data.py --count=1000 --output=commander_synthetic_state.json
Run the core orchestrator locally in simulation mode:

Bash

python src/commander/main.py --mode=simulate --config=config/local.yaml
Force-purge all quantum states (DANGEROUS):

Bash

./scripts/purge_quantum_states.sh --confirm
